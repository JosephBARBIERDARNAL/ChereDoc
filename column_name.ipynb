{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9731904-3eba-48e9-ab5b-e03293e55f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0959e92c-9728-4206-a6ff-8594f2de956d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_column_names(directory, wave):\n",
    "    \n",
    "    distinct_columns = set()\n",
    "\n",
    "    # Iterating over each .dta file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.dta'):\n",
    "\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            data = pd.read_stata(filepath, convert_categoricals=False)\n",
    "            distinct_columns.update(data.columns)\n",
    "\n",
    "    # lowerize and sort the columns name\n",
    "    distinct_columns = [col_name.lower() for col_name in distinct_columns]\n",
    "    distinct_columns = sorted(distinct_columns)\n",
    "    \n",
    "    # Saving the distinct column names to a file\n",
    "    with open(f'data/column_names/column_names_wave{wave}.txt', 'w') as file:\n",
    "        for column in distinct_columns:\n",
    "            file.write(column + '\\n')\n",
    "\n",
    "    print(\"Distinct column names saved\")\n",
    "    \n",
    "    return distinct_columns\n",
    "\n",
    "\n",
    "def get_column_names(wave, path_to_txt='data/column_names/'):\n",
    "    \n",
    "    column_names = []\n",
    "    with open(f'{path_to_txt}column_names_wave{str(wave)}.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            column_names.append(line.strip())\n",
    "            \n",
    "    return column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8213e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct column names saved\n",
      "Wave 1 has 2201 columns\n",
      "\n",
      "Distinct column names saved\n",
      "Wave 2 has 2496 columns\n",
      "\n",
      "Distinct column names saved\n",
      "Wave 3 has 3264 columns\n",
      "\n",
      "Distinct column names saved\n",
      "Wave 4 has 4203 columns\n",
      "\n",
      "Distinct column names saved\n",
      "Wave 5 has 3816 columns\n",
      "\n",
      "Distinct column names saved\n",
      "Wave 6 has 5406 columns\n",
      "\n",
      "Distinct column names saved\n",
      "Wave 7 has 8014 columns\n",
      "\n",
      "Distinct column names saved\n",
      "Wave 8 has 6478 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for wave in range(1, 9):\n",
    "    directory = f'../SHARE/data/sharew{wave}_rel8-0-0_ALL_datasets_stata/'\n",
    "    column_names = save_column_names(directory, wave)\n",
    "    print(f\"Wave {wave} has {len(column_names)} columns\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
